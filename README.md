# RAG_FASHION_CHATBOT
# ğŸ§µ Taarini Threads Assistant

A fashion-focused AI assistant for answering queries about products, policies, and collections using **Retrieval-Augmented Generation (RAG)**. Built using **LangChain**, **FAISS**, **Hugging Face Embeddings**, and **Streamlit**, and powered by **Groq's LLaMA 3** models.

---

## âœ¨ Features

- ğŸ’¬ Natural language chat with product catalog and brand policies
- ğŸ” Search products using semantic similarity with FAISS
- ğŸ¯ Filter products by price (e.g., "under Rs 3000")
- â­ Sort products by customer ratings
- ğŸ“‘ Answer brand-specific questions using policy documents
- âœ… RAG-based architecture using LLM and vector DB
- âš¡ Fast inference using Groq API

---

## ğŸš€ Demo

![screenshot](assets/Screenshot.png) <!-- optional: replace or remove if not available -->

---

## ğŸ“ Folder Structure
taarini-assistant/
â”‚
â”œâ”€â”€ app.py # Streamlit frontend + LLM interaction
â”œâ”€â”€ rag_fashion_chatbot.py # RAG pipeline and vector DB creation
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ .env.example # Template for environment variables
â”œâ”€â”€ README.md # You're here!
â”‚
â”œâ”€â”€ Knowledgebase/
â”‚ â”œâ”€â”€ Product_metadata.json # Product catalog (JSON format)
â”‚ â””â”€â”€ policies/ # Brand policies (e.g., shipping, return)
â”‚ â”œâ”€â”€ shipping.txt
â”‚ â””â”€â”€ return.txt
â”‚
â”œâ”€â”€ faiss_index/ # Vector DB index created by FAISS
â”œâ”€â”€ assets/
â”‚ â””â”€â”€ screenshot.png # Optional: UI image for demo


---

## ğŸ› ï¸ Tech Stack

| Component        | Tool/Library                          |
|------------------|----------------------------------------|
| Vector DB        | FAISS                                 |
| Embeddings       | HuggingFace (MiniLM)                  |
| LLM              | Groq (LLaMA 3 via `langchain_groq`)   |
| Frontend         | Streamlit                             |
| Prompting        | LangChain `PromptTemplate`            |
| Text Splitting   | LangChain's `RecursiveCharacterTextSplitter` |
| RAG Pipeline     | Custom with context injection         |

---

## âš™ï¸ Installation

```bash
# Clone the repo
git clone https://github.com/your-username/taarini-assistant.git
cd taarini-assistant

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # or .venv\Scripts\activate on Windows

# Install dependencies
pip install -r requirements.txt
```

##ğŸ§  Building the Vector DB
Before running the assistant, build the FAISS vector store:

bash
```
python rag_fashion_chatbot.py
```
##ğŸ’» Run the Assistant
bash
```
streamlit run app.py
```
Then open http://localhost:8501 in your browser.

